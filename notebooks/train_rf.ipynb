{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import sys\n",
    "sys.path.append('./src/misc')\n",
    "import tools\n",
    "import sql_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"./src/sql/\"\n",
    "data = sql_tools.read_database(path_to_data+\"trailing_database.db\", \"5_game_trailing\")\n",
    "data = data[data['O/U_line']!='']\n",
    "data['O/U_result'] = data.apply(lambda row: tools.OU(row['O/U_line'],float(row['total'])),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>game_date</th>\n",
       "      <th>teamAbbr</th>\n",
       "      <th>opptAbbr</th>\n",
       "      <th>total</th>\n",
       "      <th>O/U_line</th>\n",
       "      <th>spread</th>\n",
       "      <th>teamMIN</th>\n",
       "      <th>teamFGM</th>\n",
       "      <th>teamFGA</th>\n",
       "      <th>...</th>\n",
       "      <th>opptAST_RATIO_RANK</th>\n",
       "      <th>opptOREB_PCT_RANK</th>\n",
       "      <th>opptDREB_PCT_RANK</th>\n",
       "      <th>opptREB_PCT_RANK</th>\n",
       "      <th>opptTM_TOV_PCT_RANK</th>\n",
       "      <th>opptEFG_PCT_RANK</th>\n",
       "      <th>opptTS_PCT_RANK</th>\n",
       "      <th>opptPACE_RANK</th>\n",
       "      <th>opptPIE_RANK</th>\n",
       "      <th>O/U_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-23</td>\n",
       "      <td>2023-05-17 00:00:00</td>\n",
       "      <td>BOS</td>\n",
       "      <td>MIA</td>\n",
       "      <td>239</td>\n",
       "      <td>212.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>89.6</td>\n",
       "      <td>...</td>\n",
       "      <td>489.8</td>\n",
       "      <td>1559.2</td>\n",
       "      <td>1420.8</td>\n",
       "      <td>1529.8</td>\n",
       "      <td>1289.2</td>\n",
       "      <td>610.0</td>\n",
       "      <td>548.6</td>\n",
       "      <td>1028.6</td>\n",
       "      <td>1161.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-23</td>\n",
       "      <td>2023-05-16 00:00:00</td>\n",
       "      <td>DEN</td>\n",
       "      <td>LAL</td>\n",
       "      <td>258</td>\n",
       "      <td>222.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>41.6</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1573.4</td>\n",
       "      <td>885.8</td>\n",
       "      <td>1252.8</td>\n",
       "      <td>1194.2</td>\n",
       "      <td>687.6</td>\n",
       "      <td>1663.2</td>\n",
       "      <td>1790.6</td>\n",
       "      <td>992.2</td>\n",
       "      <td>1516.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-23</td>\n",
       "      <td>2023-05-14 00:00:00</td>\n",
       "      <td>BOS</td>\n",
       "      <td>PHI</td>\n",
       "      <td>200</td>\n",
       "      <td>201.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>89.6</td>\n",
       "      <td>...</td>\n",
       "      <td>592.0</td>\n",
       "      <td>1285.4</td>\n",
       "      <td>844.0</td>\n",
       "      <td>947.6</td>\n",
       "      <td>1230.6</td>\n",
       "      <td>797.0</td>\n",
       "      <td>859.0</td>\n",
       "      <td>1375.0</td>\n",
       "      <td>929.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-23</td>\n",
       "      <td>2023-05-12 00:00:00</td>\n",
       "      <td>LAL</td>\n",
       "      <td>GSW</td>\n",
       "      <td>223</td>\n",
       "      <td>218.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>49.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>867.8</td>\n",
       "      <td>791.4</td>\n",
       "      <td>1384.0</td>\n",
       "      <td>1118.2</td>\n",
       "      <td>922.6</td>\n",
       "      <td>1462.8</td>\n",
       "      <td>1541.6</td>\n",
       "      <td>1536.2</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-23</td>\n",
       "      <td>2023-05-12 00:00:00</td>\n",
       "      <td>MIA</td>\n",
       "      <td>NYK</td>\n",
       "      <td>188</td>\n",
       "      <td>204.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>42.6</td>\n",
       "      <td>86.2</td>\n",
       "      <td>...</td>\n",
       "      <td>857.8</td>\n",
       "      <td>1357.8</td>\n",
       "      <td>1687.6</td>\n",
       "      <td>1528.6</td>\n",
       "      <td>1367.8</td>\n",
       "      <td>1141.2</td>\n",
       "      <td>1191.4</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>1496.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7507</th>\n",
       "      <td>2017-18</td>\n",
       "      <td>2017-10-20 00:00:00</td>\n",
       "      <td>PHX</td>\n",
       "      <td>LAL</td>\n",
       "      <td>262</td>\n",
       "      <td>220.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>953.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>1588.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>2279.0</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>1654.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7508</th>\n",
       "      <td>2017-18</td>\n",
       "      <td>2017-10-20 00:00:00</td>\n",
       "      <td>BKN</td>\n",
       "      <td>ORL</td>\n",
       "      <td>247</td>\n",
       "      <td>226.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>1588.0</td>\n",
       "      <td>1114.0</td>\n",
       "      <td>1678.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7509</th>\n",
       "      <td>2017-18</td>\n",
       "      <td>2017-10-20 00:00:00</td>\n",
       "      <td>MIN</td>\n",
       "      <td>UTA</td>\n",
       "      <td>197</td>\n",
       "      <td>197.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>2147.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>1792.0</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>1675.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7510</th>\n",
       "      <td>2017-18</td>\n",
       "      <td>2017-10-20 00:00:00</td>\n",
       "      <td>DAL</td>\n",
       "      <td>SAC</td>\n",
       "      <td>181</td>\n",
       "      <td>202.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>2272.0</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>905.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7511</th>\n",
       "      <td>2017-18</td>\n",
       "      <td>2017-10-20 00:00:00</td>\n",
       "      <td>NOP</td>\n",
       "      <td>GSW</td>\n",
       "      <td>248</td>\n",
       "      <td>221.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>1649.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>2101.0</td>\n",
       "      <td>2037.0</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7488 rows × 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       season            game_date teamAbbr opptAbbr  total O/U_line  spread   \n",
       "0     2022-23  2023-05-17 00:00:00      BOS      MIA    239    212.0     8.5  \\\n",
       "1     2022-23  2023-05-16 00:00:00      DEN      LAL    258    222.5     7.0   \n",
       "2     2022-23  2023-05-14 00:00:00      BOS      PHI    200    201.5     6.0   \n",
       "3     2022-23  2023-05-12 00:00:00      LAL      GSW    223    218.0     3.5   \n",
       "4     2022-23  2023-05-12 00:00:00      MIA      NYK    188    204.5     6.5   \n",
       "...       ...                  ...      ...      ...    ...      ...     ...   \n",
       "7507  2017-18  2017-10-20 00:00:00      PHX      LAL    262    220.5     3.5   \n",
       "7508  2017-18  2017-10-20 00:00:00      BKN      ORL    247    226.5     2.0   \n",
       "7509  2017-18  2017-10-20 00:00:00      MIN      UTA    197    197.0     4.5   \n",
       "7510  2017-18  2017-10-20 00:00:00      DAL      SAC    181    202.0     6.0   \n",
       "7511  2017-18  2017-10-20 00:00:00      NOP      GSW    248    221.0     9.0   \n",
       "\n",
       "      teamMIN  teamFGM  teamFGA  ...  opptAST_RATIO_RANK  opptOREB_PCT_RANK   \n",
       "0        48.0     42.8     89.6  ...               489.8             1559.2  \\\n",
       "1        48.0     41.6     91.0  ...              1573.4              885.8   \n",
       "2        48.0     42.8     89.6  ...               592.0             1285.4   \n",
       "3        49.0     47.0     92.0  ...               867.8              791.4   \n",
       "4        48.0     42.6     86.2  ...               857.8             1357.8   \n",
       "...       ...      ...      ...  ...                 ...                ...   \n",
       "7507     48.0     28.0     89.0  ...               953.0              187.0   \n",
       "7508     48.0     45.0     94.0  ...              2007.0              597.0   \n",
       "7509     48.0     37.0     85.0  ...              1017.0             1535.0   \n",
       "7510     48.0     38.0     86.0  ...              2005.0              597.0   \n",
       "7511     48.0     30.0     79.0  ...              1001.0             1649.0   \n",
       "\n",
       "      opptDREB_PCT_RANK  opptREB_PCT_RANK  opptTM_TOV_PCT_RANK   \n",
       "0                1420.8            1529.8               1289.2  \\\n",
       "1                1252.8            1194.2                687.6   \n",
       "2                 844.0             947.6               1230.6   \n",
       "3                1384.0            1118.2                922.6   \n",
       "4                1687.6            1528.6               1367.8   \n",
       "...                 ...               ...                  ...   \n",
       "7507             1588.0             646.0               2279.0   \n",
       "7508             1588.0            1114.0               1678.0   \n",
       "7509             2147.0            2154.0               1054.0   \n",
       "7510             2272.0            1710.0               1933.0   \n",
       "7511              762.0            1625.0                682.0   \n",
       "\n",
       "      opptEFG_PCT_RANK  opptTS_PCT_RANK  opptPACE_RANK  opptPIE_RANK   \n",
       "0                610.0            548.6         1028.6        1161.2  \\\n",
       "1               1663.2           1790.6          992.2        1516.4   \n",
       "2                797.0            859.0         1375.0         929.2   \n",
       "3               1462.8           1541.6         1536.2        1045.0   \n",
       "4               1141.2           1191.4         1211.0        1496.8   \n",
       "...                ...              ...            ...           ...   \n",
       "7507            1603.0           1654.0          857.0         120.0   \n",
       "7508            1939.0           1368.0          857.0         911.0   \n",
       "7509            1792.0           1764.0         1675.0        1837.0   \n",
       "7510             905.0            523.0            3.0        1856.0   \n",
       "7511            2101.0           2037.0         1063.0        1154.0   \n",
       "\n",
       "      O/U_result  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              0  \n",
       "...          ...  \n",
       "7507           1  \n",
       "7508           1  \n",
       "7509           2  \n",
       "7510           0  \n",
       "7511           1  \n",
       "\n",
       "[7488 rows x 172 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = tools.model_preprocessing(data,(\"2016-01-10\",\"2023-12-12\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:16<05:22, 16.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [1, 1, 1, 1, 1, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n",
      "Trial 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:33<05:05, 16.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n",
      "Trial 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:50<04:46, 16.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 0, 0, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   70.0\n",
      "Trial 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [01:07<04:30, 16.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   60.0\n",
      "Trial 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [01:24<04:12, 16.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n",
      "Trial 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [01:41<03:55, 16.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   60.0\n",
      "Trial 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [01:58<03:39, 16.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n",
      "Trial 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [02:15<03:23, 16.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   60.0\n",
      "Trial 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [02:32<03:05, 16.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n",
      "Trial 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [02:49<02:49, 16.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 0, 1, 1, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n",
      "Trial 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [03:06<02:32, 16.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 0, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   60.0\n",
      "Trial 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [03:22<02:15, 16.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n",
      "Trial 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [03:40<01:58, 16.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 0, 0, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   70.0\n",
      "Trial 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [03:57<01:42, 17.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n",
      "Trial 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [04:14<01:25, 17.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 1, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   40.0\n",
      "Trial 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [04:31<01:07, 16.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n",
      "Trial 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [04:47<00:50, 16.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 1, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   40.0\n",
      "Trial 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [05:04<00:33, 16.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n",
      "Trial 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [05:21<00:16, 16.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [1, 0, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   70.0\n",
      "Trial 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [05:38<00:00, 16.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n = 15\n",
    "n_estimators = 50\n",
    "n_trials = 10\n",
    "OU_results = list(y[-n:])\n",
    "\n",
    "acc_vals = []\n",
    "\n",
    "print(f\"Backtesting for {n} games with {n_estimators} estimators with {n_trials} trials.\\n\")\n",
    "for trial in tqdm(range(0,n_trials)):\n",
    "    pred = []\n",
    "    for i in range(0,n):\n",
    "        rf_model = RandomForestClassifier(n_estimators=n_estimators)\n",
    "        \n",
    "        X_train = X[n+1-i:]\n",
    "        y_train = y[n+1-i:]\n",
    "        \n",
    "        X_test = X[n-i]\n",
    "        y_test = y[n-i]\n",
    "        \n",
    "        rf_model.fit(X_train,y_train)\n",
    "        yhat = rf_model.predict(X_test.reshape(1, -1))\n",
    "        \n",
    "        pred.append(yhat[0])\n",
    "\n",
    "    acc = tools.score_results(OU_results,pred)\n",
    "    acc_vals.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5399999999999999"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_acc = sum(acc_vals)/len(acc_vals)\n",
    "print(f\"Random Forest Classifier achieved {overall_acc*100}% overall accruacy for the past {n} games. Accuracy is calculated from {20} trials.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "130/130 [==============================] - 2s 13ms/step - loss: 0.7984 - accuracy: 0.4814 - val_loss: 0.7614 - val_accuracy: 0.4951\n",
      "Epoch 2/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7575 - accuracy: 0.4940 - val_loss: 0.7607 - val_accuracy: 0.5160\n",
      "Epoch 3/120\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.7570 - accuracy: 0.5011 - val_loss: 0.7623 - val_accuracy: 0.4729\n",
      "Epoch 4/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7566 - accuracy: 0.4952 - val_loss: 0.7702 - val_accuracy: 0.4687\n",
      "Epoch 5/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7570 - accuracy: 0.5017 - val_loss: 0.7615 - val_accuracy: 0.5174\n",
      "Epoch 6/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7538 - accuracy: 0.5193 - val_loss: 0.7680 - val_accuracy: 0.4687\n",
      "Epoch 7/120\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.7543 - accuracy: 0.5096 - val_loss: 0.7604 - val_accuracy: 0.5160\n",
      "Epoch 8/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7548 - accuracy: 0.5054 - val_loss: 0.7656 - val_accuracy: 0.4645\n",
      "Epoch 9/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7541 - accuracy: 0.5122 - val_loss: 0.7754 - val_accuracy: 0.4687\n",
      "Epoch 10/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7533 - accuracy: 0.5182 - val_loss: 0.7609 - val_accuracy: 0.5271\n",
      "Epoch 11/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7547 - accuracy: 0.5093 - val_loss: 0.7612 - val_accuracy: 0.5257\n",
      "Epoch 12/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7530 - accuracy: 0.5210 - val_loss: 0.7619 - val_accuracy: 0.5007\n",
      "Epoch 13/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7514 - accuracy: 0.5215 - val_loss: 0.7631 - val_accuracy: 0.5035\n",
      "Epoch 14/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7513 - accuracy: 0.5311 - val_loss: 0.7652 - val_accuracy: 0.4771\n",
      "Epoch 15/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7526 - accuracy: 0.5148 - val_loss: 0.7609 - val_accuracy: 0.5216\n",
      "Epoch 16/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7508 - accuracy: 0.5266 - val_loss: 0.7600 - val_accuracy: 0.5257\n",
      "Epoch 17/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7512 - accuracy: 0.5252 - val_loss: 0.7593 - val_accuracy: 0.5271\n",
      "Epoch 18/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7518 - accuracy: 0.5226 - val_loss: 0.7630 - val_accuracy: 0.5049\n",
      "Epoch 19/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7503 - accuracy: 0.5323 - val_loss: 0.7634 - val_accuracy: 0.4993\n",
      "Epoch 20/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7481 - accuracy: 0.5535 - val_loss: 0.7603 - val_accuracy: 0.5313\n",
      "Epoch 21/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7495 - accuracy: 0.5309 - val_loss: 0.7608 - val_accuracy: 0.5271\n",
      "Epoch 22/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7470 - accuracy: 0.5385 - val_loss: 0.7609 - val_accuracy: 0.5188\n",
      "Epoch 23/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7473 - accuracy: 0.5391 - val_loss: 0.7580 - val_accuracy: 0.5299\n",
      "Epoch 24/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7459 - accuracy: 0.5436 - val_loss: 0.7576 - val_accuracy: 0.5369\n",
      "Epoch 25/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7460 - accuracy: 0.5436 - val_loss: 0.7577 - val_accuracy: 0.5313\n",
      "Epoch 26/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7453 - accuracy: 0.5468 - val_loss: 0.7631 - val_accuracy: 0.5299\n",
      "Epoch 27/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7452 - accuracy: 0.5475 - val_loss: 0.7577 - val_accuracy: 0.5327\n",
      "Epoch 28/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7430 - accuracy: 0.5598 - val_loss: 0.7636 - val_accuracy: 0.5271\n",
      "Epoch 29/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7416 - accuracy: 0.5588 - val_loss: 0.7604 - val_accuracy: 0.5299\n",
      "Epoch 30/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7415 - accuracy: 0.5538 - val_loss: 0.7566 - val_accuracy: 0.5369\n",
      "Epoch 31/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7409 - accuracy: 0.5625 - val_loss: 0.7582 - val_accuracy: 0.5396\n",
      "Epoch 32/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7398 - accuracy: 0.5605 - val_loss: 0.7569 - val_accuracy: 0.5327\n",
      "Epoch 33/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7422 - accuracy: 0.5533 - val_loss: 0.7564 - val_accuracy: 0.5341\n",
      "Epoch 34/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7386 - accuracy: 0.5725 - val_loss: 0.7607 - val_accuracy: 0.5438\n",
      "Epoch 35/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7375 - accuracy: 0.5694 - val_loss: 0.7562 - val_accuracy: 0.5508\n",
      "Epoch 36/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7367 - accuracy: 0.5651 - val_loss: 0.7538 - val_accuracy: 0.5522\n",
      "Epoch 37/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7341 - accuracy: 0.5843 - val_loss: 0.7579 - val_accuracy: 0.5355\n",
      "Epoch 38/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7337 - accuracy: 0.5807 - val_loss: 0.7555 - val_accuracy: 0.5605\n",
      "Epoch 39/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7319 - accuracy: 0.5889 - val_loss: 0.7505 - val_accuracy: 0.5549\n",
      "Epoch 40/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7290 - accuracy: 0.5997 - val_loss: 0.7594 - val_accuracy: 0.5313\n",
      "Epoch 41/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7300 - accuracy: 0.5815 - val_loss: 0.7536 - val_accuracy: 0.5633\n",
      "Epoch 42/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7273 - accuracy: 0.5901 - val_loss: 0.7553 - val_accuracy: 0.5396\n",
      "Epoch 43/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7247 - accuracy: 0.5940 - val_loss: 0.7467 - val_accuracy: 0.5800\n",
      "Epoch 44/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7250 - accuracy: 0.6003 - val_loss: 0.7483 - val_accuracy: 0.5828\n",
      "Epoch 45/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7234 - accuracy: 0.5985 - val_loss: 0.7446 - val_accuracy: 0.5841\n",
      "Epoch 46/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7168 - accuracy: 0.6156 - val_loss: 0.7419 - val_accuracy: 0.5855\n",
      "Epoch 47/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7161 - accuracy: 0.6183 - val_loss: 0.7453 - val_accuracy: 0.5828\n",
      "Epoch 48/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7164 - accuracy: 0.6033 - val_loss: 0.7426 - val_accuracy: 0.5661\n",
      "Epoch 49/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7128 - accuracy: 0.6156 - val_loss: 0.7368 - val_accuracy: 0.6106\n",
      "Epoch 50/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7108 - accuracy: 0.6246 - val_loss: 0.7364 - val_accuracy: 0.6078\n",
      "Epoch 51/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7103 - accuracy: 0.6218 - val_loss: 0.7326 - val_accuracy: 0.5953\n",
      "Epoch 52/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7069 - accuracy: 0.6296 - val_loss: 0.7353 - val_accuracy: 0.5786\n",
      "Epoch 53/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.7055 - accuracy: 0.6368 - val_loss: 0.7287 - val_accuracy: 0.6259\n",
      "Epoch 54/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.7012 - accuracy: 0.6390 - val_loss: 0.7247 - val_accuracy: 0.6342\n",
      "Epoch 55/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.6985 - accuracy: 0.6432 - val_loss: 0.7395 - val_accuracy: 0.5508\n",
      "Epoch 56/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.6956 - accuracy: 0.6384 - val_loss: 0.7230 - val_accuracy: 0.6050\n",
      "Epoch 57/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.6939 - accuracy: 0.6543 - val_loss: 0.7159 - val_accuracy: 0.6439\n",
      "Epoch 58/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.6921 - accuracy: 0.6565 - val_loss: 0.7121 - val_accuracy: 0.6579\n",
      "Epoch 59/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.6827 - accuracy: 0.6710 - val_loss: 0.7145 - val_accuracy: 0.6189\n",
      "Epoch 60/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.6834 - accuracy: 0.6681 - val_loss: 0.7065 - val_accuracy: 0.6704\n",
      "Epoch 61/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.6829 - accuracy: 0.6518 - val_loss: 0.7062 - val_accuracy: 0.6551\n",
      "Epoch 62/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.6788 - accuracy: 0.6710 - val_loss: 0.7053 - val_accuracy: 0.6551\n",
      "Epoch 63/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.6739 - accuracy: 0.6840 - val_loss: 0.6970 - val_accuracy: 0.6676\n",
      "Epoch 64/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.6685 - accuracy: 0.6917 - val_loss: 0.7096 - val_accuracy: 0.5814\n",
      "Epoch 65/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.6637 - accuracy: 0.6905 - val_loss: 0.7105 - val_accuracy: 0.5772\n",
      "Epoch 66/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.6668 - accuracy: 0.6909 - val_loss: 0.6870 - val_accuracy: 0.6857\n",
      "Epoch 67/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.6630 - accuracy: 0.6793 - val_loss: 0.6799 - val_accuracy: 0.7121\n",
      "Epoch 68/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.6541 - accuracy: 0.7163 - val_loss: 0.6790 - val_accuracy: 0.6885\n",
      "Epoch 69/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.6495 - accuracy: 0.7178 - val_loss: 0.6746 - val_accuracy: 0.6954\n",
      "Epoch 70/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.6477 - accuracy: 0.7169 - val_loss: 0.6733 - val_accuracy: 0.6829\n",
      "Epoch 71/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.6449 - accuracy: 0.7165 - val_loss: 0.6671 - val_accuracy: 0.7330\n",
      "Epoch 72/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.6417 - accuracy: 0.7168 - val_loss: 0.6580 - val_accuracy: 0.7552\n",
      "Epoch 73/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.6346 - accuracy: 0.7308 - val_loss: 0.6686 - val_accuracy: 0.6940\n",
      "Epoch 74/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.6385 - accuracy: 0.7055 - val_loss: 0.6897 - val_accuracy: 0.5800\n",
      "Epoch 75/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.6289 - accuracy: 0.7301 - val_loss: 0.6930 - val_accuracy: 0.5702\n",
      "Epoch 76/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.6253 - accuracy: 0.7362 - val_loss: 0.6560 - val_accuracy: 0.7135\n",
      "Epoch 77/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.6244 - accuracy: 0.7331 - val_loss: 0.7054 - val_accuracy: 0.5619\n",
      "Epoch 78/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.6123 - accuracy: 0.7502 - val_loss: 0.6558 - val_accuracy: 0.6634\n",
      "Epoch 79/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.6090 - accuracy: 0.7540 - val_loss: 0.6301 - val_accuracy: 0.7928\n",
      "Epoch 80/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.6067 - accuracy: 0.7509 - val_loss: 0.6947 - val_accuracy: 0.5661\n",
      "Epoch 81/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.6005 - accuracy: 0.7639 - val_loss: 0.6270 - val_accuracy: 0.7455\n",
      "Epoch 82/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.5978 - accuracy: 0.7525 - val_loss: 0.6210 - val_accuracy: 0.7566\n",
      "Epoch 83/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.5909 - accuracy: 0.7727 - val_loss: 0.6307 - val_accuracy: 0.6898\n",
      "Epoch 84/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.5872 - accuracy: 0.7761 - val_loss: 0.6415 - val_accuracy: 0.6592\n",
      "Epoch 85/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.5906 - accuracy: 0.7525 - val_loss: 0.6105 - val_accuracy: 0.7552\n",
      "Epoch 86/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.5766 - accuracy: 0.7818 - val_loss: 0.6030 - val_accuracy: 0.7691\n",
      "Epoch 87/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.5775 - accuracy: 0.7681 - val_loss: 0.5906 - val_accuracy: 0.8122\n",
      "Epoch 88/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.5765 - accuracy: 0.7638 - val_loss: 0.5868 - val_accuracy: 0.8234\n",
      "Epoch 89/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.5684 - accuracy: 0.7760 - val_loss: 0.5980 - val_accuracy: 0.7455\n",
      "Epoch 90/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.5651 - accuracy: 0.7834 - val_loss: 0.5772 - val_accuracy: 0.8331\n",
      "Epoch 91/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.5534 - accuracy: 0.8078 - val_loss: 0.5805 - val_accuracy: 0.7942\n",
      "Epoch 92/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.5574 - accuracy: 0.7865 - val_loss: 0.5810 - val_accuracy: 0.7900\n",
      "Epoch 93/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.5527 - accuracy: 0.7962 - val_loss: 0.5688 - val_accuracy: 0.8289\n",
      "Epoch 94/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.5450 - accuracy: 0.8029 - val_loss: 0.5657 - val_accuracy: 0.8303\n",
      "Epoch 95/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.5404 - accuracy: 0.8041 - val_loss: 0.5813 - val_accuracy: 0.7663\n",
      "Epoch 96/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.5376 - accuracy: 0.8072 - val_loss: 0.5519 - val_accuracy: 0.8331\n",
      "Epoch 97/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.5287 - accuracy: 0.8159 - val_loss: 0.5719 - val_accuracy: 0.7747\n",
      "Epoch 98/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.5294 - accuracy: 0.8021 - val_loss: 0.5408 - val_accuracy: 0.8414\n",
      "Epoch 99/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.5185 - accuracy: 0.8247 - val_loss: 0.5574 - val_accuracy: 0.7650\n",
      "Epoch 100/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.5195 - accuracy: 0.8097 - val_loss: 0.5327 - val_accuracy: 0.8442\n",
      "Epoch 101/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.5231 - accuracy: 0.8016 - val_loss: 0.5361 - val_accuracy: 0.8136\n",
      "Epoch 102/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.5173 - accuracy: 0.8061 - val_loss: 0.5261 - val_accuracy: 0.8387\n",
      "Epoch 103/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.5080 - accuracy: 0.8151 - val_loss: 0.5344 - val_accuracy: 0.8053\n",
      "Epoch 104/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.5046 - accuracy: 0.8196 - val_loss: 0.5187 - val_accuracy: 0.8581\n",
      "Epoch 105/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.5023 - accuracy: 0.8140 - val_loss: 0.5320 - val_accuracy: 0.8039\n",
      "Epoch 106/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.4946 - accuracy: 0.8248 - val_loss: 0.5503 - val_accuracy: 0.7469\n",
      "Epoch 107/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.4940 - accuracy: 0.8236 - val_loss: 0.5061 - val_accuracy: 0.8526\n",
      "Epoch 108/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.4899 - accuracy: 0.8259 - val_loss: 0.5012 - val_accuracy: 0.8470\n",
      "Epoch 109/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.4897 - accuracy: 0.8242 - val_loss: 0.5001 - val_accuracy: 0.8484\n",
      "Epoch 110/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.4810 - accuracy: 0.8377 - val_loss: 0.4983 - val_accuracy: 0.8387\n",
      "Epoch 111/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.4785 - accuracy: 0.8349 - val_loss: 0.5351 - val_accuracy: 0.7510\n",
      "Epoch 112/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.4788 - accuracy: 0.8216 - val_loss: 0.4892 - val_accuracy: 0.8567\n",
      "Epoch 113/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.4698 - accuracy: 0.8374 - val_loss: 0.5024 - val_accuracy: 0.8178\n",
      "Epoch 114/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.4701 - accuracy: 0.8313 - val_loss: 0.4900 - val_accuracy: 0.8373\n",
      "Epoch 115/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.4679 - accuracy: 0.8313 - val_loss: 0.4899 - val_accuracy: 0.8470\n",
      "Epoch 116/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.4632 - accuracy: 0.8377 - val_loss: 0.4975 - val_accuracy: 0.8234\n",
      "Epoch 117/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.4596 - accuracy: 0.8409 - val_loss: 0.4844 - val_accuracy: 0.8331\n",
      "Epoch 118/120\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.4584 - accuracy: 0.8370 - val_loss: 0.4706 - val_accuracy: 0.8470\n",
      "Epoch 119/120\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.4553 - accuracy: 0.8370 - val_loss: 0.4645 - val_accuracy: 0.8498\n",
      "Epoch 120/120\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.4566 - accuracy: 0.8349 - val_loss: 0.4682 - val_accuracy: 0.8442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3e1ebbf70>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#earling stopping\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = X[0].shape))\n",
    "model.add(tf.keras.layers.Dense(128, activation=\"relu6\"))\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "model.add(tf.keras.layers.Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X[301:], \n",
    "          y[301:], \n",
    "          epochs=120, \n",
    "          validation_split=0.1, \n",
    "          batch_size=50,\n",
    "          verbose=1,\n",
    "          callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for 300 games with 1 trials.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:08<00:00, 34.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural network achieved 51.33333333333333% overall accruacy for the past 300 games. Accuracy is calculated from 1 trials.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Backtesting for {n} games with {n_trials} trials.\\n\")\n",
    "\n",
    "n = 300\n",
    "OU_results = list(y[-n:])\n",
    "pred = []\n",
    "acc_vals = []\n",
    "\n",
    "for i in tqdm(range(0,n)):\n",
    "  #X_train = X[n+1-i:]\n",
    "  #y_train = y[n+1-i:]\n",
    "  \n",
    "  \"\"\"if i%10:\n",
    "      model.fit(X[n+1-i:], \n",
    "          y[n+1-i:], \n",
    "          epochs=100, \n",
    "          validation_split=0.1, \n",
    "          batch_size=100,\n",
    "          callbacks=[callback])\"\"\"\n",
    "\n",
    "  X_test = X[n-i]\n",
    "  y_test = y[n-i]\n",
    "  \n",
    "  prediction_output = model.predict(X_test.reshape(1,-1),verbose=0)\n",
    "  pred.append(tools.prediction_classifier(prediction_output)[0])\n",
    "\n",
    "acc = tools.score_results(OU_results,pred)\n",
    "acc_vals.append(acc)\n",
    "  \n",
    "overall_acc = sum(acc_vals)/len(acc_vals)\n",
    "print(f\"\\nNeural network achieved {overall_acc*100}% overall accruacy for the past {n} games. Accuracy is calculated from {n_trials} trials.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, LSTM, Dense, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X,y = tools.model_preprocessing(data,(\"2016-01-10\",\"2023-12-12\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# Define the neural network structure\n",
    "model = Sequential()\n",
    "\n",
    "# Recurrent layer (LSTM)\n",
    "model.add(LSTM(64, activation='relu', input_shape=(166, 1)))\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))  # Output layer with softmax activation for three-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/logange/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/keras/engine/training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/logange/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/keras/engine/training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/logange/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/keras/engine/training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/logange/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/keras/engine/training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"/Users/logange/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/logange/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_50' (type Sequential).\n    \n    Input 0 of layer \"lstm_6\" is incompatible with the layer: expected ndim=3, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'sequential_50' (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[275], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[1;32m      2\u001b[0m pred_labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(pred, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# Evaluate the model\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/zn/1g8s0bdx5rbdjt31b696w2nm0000gn/T/__autograph_generated_filer44k0xz9.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/logange/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/keras/engine/training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/logange/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/keras/engine/training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/logange/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/keras/engine/training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/logange/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/keras/engine/training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"/Users/logange/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/logange/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_50' (type Sequential).\n    \n    Input 0 of layer \"lstm_6\" is incompatible with the layer: expected ndim=3, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'sequential_50' (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred_labels = np.argmax(pred, axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_categorical)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove tied games (which account for only 1% of games) for binary logistic regression model\n",
    "X,y = tools.model_preprocessing(data[data['O/U_result']!=2],(\"2017-01-10\",\"2023-12-12\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logr = LogisticRegression()\n",
    "logr.fit( X[30:], y[30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41379310344827586"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logr.predict(X[300].reshape(1,-1))\n",
    "logr.score(X[:29],y[:29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting for 20 games with 1 trials.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 13/300 [00:14<05:16,  1.10s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[281], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m   X_test \u001b[39m=\u001b[39m X[n\u001b[39m-\u001b[39mi]\n\u001b[1;32m     21\u001b[0m   y_test \u001b[39m=\u001b[39m y[n\u001b[39m-\u001b[39mi]\n\u001b[0;32m---> 23\u001b[0m   prediction_output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test\u001b[39m.\u001b[39;49mreshape(\u001b[39m1\u001b[39;49m,\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m),verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     24\u001b[0m   pred\u001b[39m.\u001b[39mappend(tools\u001b[39m.\u001b[39mprediction_classifier(prediction_output)[\u001b[39m0\u001b[39m])\n\u001b[1;32m     26\u001b[0m acc \u001b[39m=\u001b[39m tools\u001b[39m.\u001b[39mscore_results(OU_results,pred)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/keras/engine/training.py:2382\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2380\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   2381\u001b[0m     callbacks\u001b[39m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 2382\u001b[0m     tmp_batch_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_function(iterator)\n\u001b[1;32m   2383\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   2384\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    931\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    934\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    935\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    936\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow_silicon/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f\"Backtesting for {n} games with {n_trials} trials.\\n\")\n",
    "\n",
    "n = 300\n",
    "OU_results = list(y[-n:])\n",
    "pred = []\n",
    "acc_vals = []\n",
    "\n",
    "for i in tqdm(range(0,n)):\n",
    "  #X_train = X[n+1-i:]\n",
    "  #y_train = y[n+1-i:]\n",
    "  \n",
    "  \"\"\"if i%10:\n",
    "      model.fit(X[n+1-i:], \n",
    "          y[n+1-i:], \n",
    "          epochs=100, \n",
    "          validation_split=0.1, \n",
    "          batch_size=100,\n",
    "          callbacks=[callback])\"\"\"\n",
    "\n",
    "  X_test = X[n-i]\n",
    "  y_test = y[n-i]\n",
    "  \n",
    "  prediction_output = model.predict(X_test.reshape(1,-1),verbose=0)\n",
    "  pred.append(tools.prediction_classifier(prediction_output)[0])\n",
    "\n",
    "acc = tools.score_results(OU_results,pred)\n",
    "acc_vals.append(acc)\n",
    "  \n",
    "overall_acc = sum(acc_vals)/len(acc_vals)\n",
    "print(f\"\\nNeural network achieved {overall_acc*100}% overall accruacy for the past {n} games. Accuracy is calculated from {n_trials} trials.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_silicon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
