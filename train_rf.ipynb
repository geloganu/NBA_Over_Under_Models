{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import sys\n",
    "sys.path.append('./src/misc')\n",
    "import tools\n",
    "import sql_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"./src/sql/\"\n",
    "data = sql_tools.read_database(path_to_data+\"trailing_database.db\", \"5_game_trailing\")\n",
    "data = data[data['O/U_line']!='']\n",
    "data['O/U_result'] = data.apply(lambda row: tools.OU(row['O/U_line'],float(row['total'])),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = tools.model_preprocessing(data,(\"2016-01-10\",\"2023-12-12\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:16<05:22, 16.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [1, 1, 1, 1, 1, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n",
      "Trial 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:33<05:05, 16.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n",
      "Trial 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:50<04:46, 16.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 0, 0, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   70.0\n",
      "Trial 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [01:07<04:30, 16.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   60.0\n",
      "Trial 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [01:24<04:12, 16.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n",
      "Trial 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [01:41<03:55, 16.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   60.0\n",
      "Trial 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [01:58<03:39, 16.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n",
      "Trial 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [02:15<03:23, 16.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   60.0\n",
      "Trial 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [02:32<03:05, 16.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n",
      "Trial 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [02:49<02:49, 16.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 0, 1, 1, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n",
      "Trial 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [03:06<02:32, 16.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 0, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   60.0\n",
      "Trial 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [03:22<02:15, 16.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n",
      "Trial 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [03:40<01:58, 16.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 0, 0, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   70.0\n",
      "Trial 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [03:57<01:42, 17.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n",
      "Trial 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [04:14<01:25, 17.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 1, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   40.0\n",
      "Trial 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [04:31<01:07, 16.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n",
      "Trial 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [04:47<00:50, 16.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 1, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   40.0\n",
      "Trial 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [05:04<00:33, 16.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n",
      "Trial 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [05:21<00:16, 16.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [1, 0, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   70.0\n",
      "Trial 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [05:38<00:00, 16.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  [0, 1, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "true:       [1, 0, 0, 1, 0, 1, 1, 2, 0, 1]\n",
      "accuracy:   50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n = 15\n",
    "n_estimators = 50\n",
    "n_trials = 10\n",
    "OU_results = list(y[-n:])\n",
    "\n",
    "acc_vals = []\n",
    "\n",
    "print(f\"Backtesting for {n} games with {n_estimators} estimators with {n_trials} trials.\\n\")\n",
    "for trial in tqdm(range(0,n_trials)):\n",
    "    pred = []\n",
    "    for i in range(0,n):\n",
    "        rf_model = RandomForestClassifier(n_estimators=n_estimators)\n",
    "        \n",
    "        X_train = X[n+1-i:]\n",
    "        y_train = y[n+1-i:]\n",
    "        \n",
    "        X_test = X[n-i]\n",
    "        y_test = y[n-i]\n",
    "        \n",
    "        rf_model.fit(X_train,y_train)\n",
    "        yhat = rf_model.predict(X_test.reshape(1, -1))\n",
    "        \n",
    "        pred.append(yhat[0])\n",
    "\n",
    "    acc = tools.score_results(OU_results,pred)\n",
    "    acc_vals.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5399999999999999"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_acc = sum(acc_vals)/len(acc_vals)\n",
    "print(f\"Random Forest Classifier achieved {overall_acc*100}% overall accruacy for the past {n} games. Accuracy is calculated from {20} trials.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#earling stopping\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = X[0].shape))\n",
    "model.add(tf.keras.layers.Dense(128, activation=\"relu6\"))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.8077 - accuracy: 0.4801 - val_loss: 0.7655 - val_accuracy: 0.4687\n",
      "Epoch 2/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7606 - accuracy: 0.4927 - val_loss: 0.7695 - val_accuracy: 0.4687\n",
      "Epoch 3/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7591 - accuracy: 0.4897 - val_loss: 0.7670 - val_accuracy: 0.4687\n",
      "Epoch 4/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7582 - accuracy: 0.4981 - val_loss: 0.7667 - val_accuracy: 0.4687\n",
      "Epoch 5/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7576 - accuracy: 0.4970 - val_loss: 0.7611 - val_accuracy: 0.5174\n",
      "Epoch 6/100\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.7585 - accuracy: 0.4920 - val_loss: 0.7606 - val_accuracy: 0.5257\n",
      "Epoch 7/100\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.7571 - accuracy: 0.4981 - val_loss: 0.7647 - val_accuracy: 0.4673\n",
      "Epoch 8/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7564 - accuracy: 0.5100 - val_loss: 0.7653 - val_accuracy: 0.4673\n",
      "Epoch 9/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7559 - accuracy: 0.5013 - val_loss: 0.7610 - val_accuracy: 0.5076\n",
      "Epoch 10/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7542 - accuracy: 0.5038 - val_loss: 0.7621 - val_accuracy: 0.5299\n",
      "Epoch 11/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7539 - accuracy: 0.5171 - val_loss: 0.7626 - val_accuracy: 0.4924\n",
      "Epoch 12/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7553 - accuracy: 0.5044 - val_loss: 0.7615 - val_accuracy: 0.5243\n",
      "Epoch 13/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7549 - accuracy: 0.5070 - val_loss: 0.7696 - val_accuracy: 0.4687\n",
      "Epoch 14/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7537 - accuracy: 0.5189 - val_loss: 0.7599 - val_accuracy: 0.5257\n",
      "Epoch 15/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7542 - accuracy: 0.5061 - val_loss: 0.7623 - val_accuracy: 0.5160\n",
      "Epoch 16/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7535 - accuracy: 0.5177 - val_loss: 0.7629 - val_accuracy: 0.4910\n",
      "Epoch 17/100\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.7519 - accuracy: 0.5293 - val_loss: 0.7603 - val_accuracy: 0.5229\n",
      "Epoch 18/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7513 - accuracy: 0.5319 - val_loss: 0.7606 - val_accuracy: 0.5271\n",
      "Epoch 19/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7498 - accuracy: 0.5372 - val_loss: 0.7613 - val_accuracy: 0.5160\n",
      "Epoch 20/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7494 - accuracy: 0.5321 - val_loss: 0.7650 - val_accuracy: 0.4854\n",
      "Epoch 21/100\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.7506 - accuracy: 0.5316 - val_loss: 0.7635 - val_accuracy: 0.4868\n",
      "Epoch 22/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7512 - accuracy: 0.5288 - val_loss: 0.7596 - val_accuracy: 0.5327\n",
      "Epoch 23/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7499 - accuracy: 0.5296 - val_loss: 0.7617 - val_accuracy: 0.5160\n",
      "Epoch 24/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7490 - accuracy: 0.5426 - val_loss: 0.7591 - val_accuracy: 0.5229\n",
      "Epoch 25/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7484 - accuracy: 0.5401 - val_loss: 0.7595 - val_accuracy: 0.5313\n",
      "Epoch 26/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7477 - accuracy: 0.5397 - val_loss: 0.7596 - val_accuracy: 0.5355\n",
      "Epoch 27/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7477 - accuracy: 0.5352 - val_loss: 0.7672 - val_accuracy: 0.4771\n",
      "Epoch 28/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7481 - accuracy: 0.5381 - val_loss: 0.7589 - val_accuracy: 0.5271\n",
      "Epoch 29/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7455 - accuracy: 0.5562 - val_loss: 0.7646 - val_accuracy: 0.4993\n",
      "Epoch 30/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7457 - accuracy: 0.5458 - val_loss: 0.7604 - val_accuracy: 0.5243\n",
      "Epoch 31/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7461 - accuracy: 0.5534 - val_loss: 0.7607 - val_accuracy: 0.5299\n",
      "Epoch 32/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7455 - accuracy: 0.5528 - val_loss: 0.7581 - val_accuracy: 0.5285\n",
      "Epoch 33/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7468 - accuracy: 0.5406 - val_loss: 0.7580 - val_accuracy: 0.5313\n",
      "Epoch 34/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7436 - accuracy: 0.5528 - val_loss: 0.7675 - val_accuracy: 0.5188\n",
      "Epoch 35/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7445 - accuracy: 0.5533 - val_loss: 0.7586 - val_accuracy: 0.5327\n",
      "Epoch 36/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7424 - accuracy: 0.5664 - val_loss: 0.7594 - val_accuracy: 0.5299\n",
      "Epoch 37/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7419 - accuracy: 0.5584 - val_loss: 0.7581 - val_accuracy: 0.5285\n",
      "Epoch 38/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7423 - accuracy: 0.5608 - val_loss: 0.7575 - val_accuracy: 0.5369\n",
      "Epoch 39/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7460 - accuracy: 0.5429 - val_loss: 0.7619 - val_accuracy: 0.5285\n",
      "Epoch 40/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7418 - accuracy: 0.5625 - val_loss: 0.7611 - val_accuracy: 0.5285\n",
      "Epoch 41/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7395 - accuracy: 0.5658 - val_loss: 0.7560 - val_accuracy: 0.5452\n",
      "Epoch 42/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7372 - accuracy: 0.5718 - val_loss: 0.7588 - val_accuracy: 0.5410\n",
      "Epoch 43/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7384 - accuracy: 0.5665 - val_loss: 0.7606 - val_accuracy: 0.5382\n",
      "Epoch 44/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7430 - accuracy: 0.5443 - val_loss: 0.7557 - val_accuracy: 0.5522\n",
      "Epoch 45/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7340 - accuracy: 0.5846 - val_loss: 0.7542 - val_accuracy: 0.5410\n",
      "Epoch 46/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7366 - accuracy: 0.5695 - val_loss: 0.7540 - val_accuracy: 0.5424\n",
      "Epoch 47/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7355 - accuracy: 0.5843 - val_loss: 0.7571 - val_accuracy: 0.5382\n",
      "Epoch 48/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7357 - accuracy: 0.5778 - val_loss: 0.7544 - val_accuracy: 0.5466\n",
      "Epoch 49/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7329 - accuracy: 0.5840 - val_loss: 0.7522 - val_accuracy: 0.5535\n",
      "Epoch 50/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7332 - accuracy: 0.5778 - val_loss: 0.7591 - val_accuracy: 0.5341\n",
      "Epoch 51/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7315 - accuracy: 0.5900 - val_loss: 0.7513 - val_accuracy: 0.5619\n",
      "Epoch 52/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7297 - accuracy: 0.5930 - val_loss: 0.7517 - val_accuracy: 0.5508\n",
      "Epoch 53/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7329 - accuracy: 0.5800 - val_loss: 0.7550 - val_accuracy: 0.5535\n",
      "Epoch 54/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7266 - accuracy: 0.6001 - val_loss: 0.7572 - val_accuracy: 0.5369\n",
      "Epoch 55/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7282 - accuracy: 0.5805 - val_loss: 0.7526 - val_accuracy: 0.5522\n",
      "Epoch 56/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7261 - accuracy: 0.5924 - val_loss: 0.7489 - val_accuracy: 0.5730\n",
      "Epoch 57/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7240 - accuracy: 0.6004 - val_loss: 0.7495 - val_accuracy: 0.5466\n",
      "Epoch 58/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7216 - accuracy: 0.6123 - val_loss: 0.7459 - val_accuracy: 0.5744\n",
      "Epoch 59/100\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.7227 - accuracy: 0.6004 - val_loss: 0.7442 - val_accuracy: 0.5939\n",
      "Epoch 60/100\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.7178 - accuracy: 0.6092 - val_loss: 0.7425 - val_accuracy: 0.5814\n",
      "Epoch 61/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7203 - accuracy: 0.6023 - val_loss: 0.7469 - val_accuracy: 0.5619\n",
      "Epoch 62/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7185 - accuracy: 0.6061 - val_loss: 0.7501 - val_accuracy: 0.5661\n",
      "Epoch 63/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7145 - accuracy: 0.6154 - val_loss: 0.7419 - val_accuracy: 0.5744\n",
      "Epoch 64/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7152 - accuracy: 0.6148 - val_loss: 0.7507 - val_accuracy: 0.5410\n",
      "Epoch 65/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7114 - accuracy: 0.6327 - val_loss: 0.7374 - val_accuracy: 0.5967\n",
      "Epoch 66/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7101 - accuracy: 0.6261 - val_loss: 0.7353 - val_accuracy: 0.6147\n",
      "Epoch 67/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7095 - accuracy: 0.6284 - val_loss: 0.7333 - val_accuracy: 0.6231\n",
      "Epoch 68/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7093 - accuracy: 0.6251 - val_loss: 0.7357 - val_accuracy: 0.5841\n",
      "Epoch 69/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7052 - accuracy: 0.6366 - val_loss: 0.7310 - val_accuracy: 0.6245\n",
      "Epoch 70/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7044 - accuracy: 0.6343 - val_loss: 0.7282 - val_accuracy: 0.6273\n",
      "Epoch 71/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7010 - accuracy: 0.6466 - val_loss: 0.7258 - val_accuracy: 0.6370\n",
      "Epoch 72/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6975 - accuracy: 0.6523 - val_loss: 0.7235 - val_accuracy: 0.6398\n",
      "Epoch 73/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.7009 - accuracy: 0.6384 - val_loss: 0.7309 - val_accuracy: 0.5800\n",
      "Epoch 74/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6986 - accuracy: 0.6400 - val_loss: 0.7196 - val_accuracy: 0.6439\n",
      "Epoch 75/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6927 - accuracy: 0.6567 - val_loss: 0.7176 - val_accuracy: 0.6481\n",
      "Epoch 76/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6894 - accuracy: 0.6641 - val_loss: 0.7144 - val_accuracy: 0.6579\n",
      "Epoch 77/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6878 - accuracy: 0.6724 - val_loss: 0.7630 - val_accuracy: 0.5271\n",
      "Epoch 78/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6908 - accuracy: 0.6483 - val_loss: 0.7137 - val_accuracy: 0.6481\n",
      "Epoch 79/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6838 - accuracy: 0.6765 - val_loss: 0.7096 - val_accuracy: 0.6634\n",
      "Epoch 80/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6787 - accuracy: 0.6871 - val_loss: 0.7054 - val_accuracy: 0.6843\n",
      "Epoch 81/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6813 - accuracy: 0.6812 - val_loss: 0.7045 - val_accuracy: 0.6759\n",
      "Epoch 82/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6777 - accuracy: 0.6768 - val_loss: 0.7242 - val_accuracy: 0.5633\n",
      "Epoch 83/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6721 - accuracy: 0.6899 - val_loss: 0.7299 - val_accuracy: 0.5480\n",
      "Epoch 84/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6718 - accuracy: 0.6859 - val_loss: 0.7162 - val_accuracy: 0.5688\n",
      "Epoch 85/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6689 - accuracy: 0.6871 - val_loss: 0.6968 - val_accuracy: 0.6773\n",
      "Epoch 86/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6659 - accuracy: 0.6961 - val_loss: 0.6984 - val_accuracy: 0.6453\n",
      "Epoch 87/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6635 - accuracy: 0.6953 - val_loss: 0.6883 - val_accuracy: 0.7079\n",
      "Epoch 88/100\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 0.6592 - accuracy: 0.7043 - val_loss: 0.6890 - val_accuracy: 0.6843\n",
      "Epoch 89/100\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.6580 - accuracy: 0.7089 - val_loss: 0.6851 - val_accuracy: 0.6996\n",
      "Epoch 90/100\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.6561 - accuracy: 0.7026 - val_loss: 0.7028 - val_accuracy: 0.5814\n",
      "Epoch 91/100\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 0.6516 - accuracy: 0.7145 - val_loss: 0.7138 - val_accuracy: 0.5563\n",
      "Epoch 92/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6509 - accuracy: 0.7077 - val_loss: 0.6722 - val_accuracy: 0.7552\n",
      "Epoch 93/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6450 - accuracy: 0.7117 - val_loss: 0.6707 - val_accuracy: 0.7191\n",
      "Epoch 94/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6442 - accuracy: 0.7114 - val_loss: 0.6786 - val_accuracy: 0.6565\n",
      "Epoch 95/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6373 - accuracy: 0.7293 - val_loss: 0.6723 - val_accuracy: 0.6773\n",
      "Epoch 96/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6356 - accuracy: 0.7295 - val_loss: 0.6603 - val_accuracy: 0.7483\n",
      "Epoch 97/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6329 - accuracy: 0.7262 - val_loss: 0.6971 - val_accuracy: 0.5744\n",
      "Epoch 98/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6351 - accuracy: 0.7275 - val_loss: 0.6517 - val_accuracy: 0.7650\n",
      "Epoch 99/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6295 - accuracy: 0.7269 - val_loss: 0.6525 - val_accuracy: 0.7399\n",
      "Epoch 100/100\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.6256 - accuracy: 0.7361 - val_loss: 0.6455 - val_accuracy: 0.7816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3196292b0>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-196-37d1c855448c>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[196], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    callbacks=[callback])\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "X,y = tools.model_preprocessing(data,(\"2017-01-10\",\"2023-12-12\"))\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "model.fit(X[301:], \n",
    "          y[301:], \n",
    "          epochs=100, \n",
    "          validation_split=0.1, \n",
    "          batch_size=100,\n",
    "          verbose=0\n",
    "          callbacks=[callback])\n",
    "\n",
    "print(f\"Backtesting for {n} games with {n_trials} trials.\\n\")\n",
    "\n",
    "n = 300\n",
    "OU_results = list(y[-n:])\n",
    "pred = []\n",
    "acc_vals = []\n",
    "\n",
    "for i in tqdm(range(0,n)):\n",
    "  #X_train = X[n+1-i:]\n",
    "  #y_train = y[n+1-i:]\n",
    "  \n",
    "  if i%10:\n",
    "      model.fit(X[n+1-i:], \n",
    "          y[n+1-i:], \n",
    "          epochs=100, \n",
    "          validation_split=0.1, \n",
    "          batch_size=100,\n",
    "          callbacks=[callback])\n",
    "\n",
    "  X_test = X[n-i]\n",
    "  y_test = y[n-i]\n",
    "  \n",
    "  prediction_output = model.predict(X_test.reshape(1,-1),verbose=0)\n",
    "  pred.append(tools.prediction_classifier(prediction_output)[0])\n",
    "\n",
    "acc = tools.score_results(OU_results,pred)\n",
    "acc_vals.append(acc)\n",
    "  \n",
    "overall_acc = sum(acc_vals)/len(acc_vals)\n",
    "print(f\"\\nNeural network achieved {overall_acc*100}% overall accruacy for the past {n} games. Accuracy is calculated from {n_trials} trials.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OU_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_silicon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
